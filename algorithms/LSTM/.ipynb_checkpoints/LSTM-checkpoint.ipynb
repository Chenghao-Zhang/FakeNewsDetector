{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b316a6",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "- text: the text of the article; could be incomplete\n",
    "- clean_news: news that is processed\n",
    "- label: a label that marks the article as potentially unreliable\n",
    "    - 1: unreliable\n",
    "    - 0: reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4116d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "from keras.layers import LSTM, Dropout, Dense, Embedding\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0921d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataframe):\n",
    "    df = dataframe\n",
    "    df = df.drop(columns=['id', 'title', 'author'], axis=1)\n",
    "    df = df.dropna(axis=0)\n",
    "    df['clean_news'] = df['text'].str.lower()\n",
    "    df['clean_news'] = df['clean_news'].str.replace('[^A-Za-z0-9\\s]', '')\n",
    "    df['clean_news'] = df['clean_news'].str.replace('\\n', '')\n",
    "    df['clean_news'] = df['clean_news'].str.replace('\\s+', ' ')\n",
    "\n",
    "    # delete stopwords and punctuation\n",
    "    stop = stopwords.words('english')\n",
    "    df['clean_news'] = df['clean_news'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243bb5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ab9f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>house dem aide didnt even see comeys letter ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>ever get feeling life circles roundabout rathe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "\n",
       "                                          clean_news  \n",
       "0  house dem aide didnt even see comeys letter ja...  \n",
       "1  ever get feeling life circles roundabout rathe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training data\n",
    "parent_path = '/Users/zch/Desktop/FakeNewsDetector/dataset/fake-news-FromKaggle/'\n",
    "df = pd.read_csv(parent_path + 'train.csv')\n",
    "df = data_process(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee57f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['clean_news'])\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fc00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding data\n",
    "sequences = tokenizer.texts_to_sequences(df['clean_news'])\n",
    "padded_seq = pad_sequences(sequences, maxlen=500, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cde6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding index\n",
    "embedding_index = {}\n",
    "with open('/Users/zch/Downloads/archive/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d23ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size+1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e88fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_seq, df['label'], test_size=0.20, random_state=42, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa206fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 18:58:12.628882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size+1, 100, weights=[embedding_matrix], trainable=False),\n",
    "    Dropout(0.2),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(256),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cffc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 60s 903ms/step - loss: 0.6327 - accuracy: 0.6382 - val_loss: 0.6294 - val_accuracy: 0.6405\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 57s 886ms/step - loss: 0.6075 - accuracy: 0.6759 - val_loss: 0.7974 - val_accuracy: 0.5639\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 57s 884ms/step - loss: 0.6512 - accuracy: 0.6092 - val_loss: 0.6077 - val_accuracy: 0.6494\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 58s 888ms/step - loss: 0.6231 - accuracy: 0.6451 - val_loss: 0.6790 - val_accuracy: 0.5601\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 58s 898ms/step - loss: 0.6533 - accuracy: 0.5960 - val_loss: 0.6185 - val_accuracy: 0.6338\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 58s 890ms/step - loss: 0.6136 - accuracy: 0.6371 - val_loss: 0.6422 - val_accuracy: 0.6841\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 58s 890ms/step - loss: 0.6721 - accuracy: 0.5854 - val_loss: 0.6513 - val_accuracy: 0.6159\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 58s 894ms/step - loss: 0.6352 - accuracy: 0.6256 - val_loss: 0.6443 - val_accuracy: 0.6147\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 58s 894ms/step - loss: 0.5900 - accuracy: 0.6973 - val_loss: 0.5072 - val_accuracy: 0.7691\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 58s 894ms/step - loss: 0.4380 - accuracy: 0.8155 - val_loss: 0.3429 - val_accuracy: 0.8599\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=256, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model\n",
    "model.save('m2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
